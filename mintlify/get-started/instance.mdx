---
title: Connect Your Database
---

import PostgreSQLConfig from '/snippets/get-started/instance/postgresql.mdx';
import OracleConfig from '/snippets/get-started/instance/oracle.mdx';
import SnowflakeConfig from '/snippets/get-started/instance/snowflake.mdx';
import MongoDBConfig from '/snippets/get-started/instance/mongodb.mdx';
import ClickHouseConfig from '/snippets/get-started/instance/clickhouse.mdx';
import DatabricksConfig from '/snippets/get-started/instance/databricks.mdx';
import SpannerConfig from '/snippets/get-started/instance/spanner.mdx';

Learn how to connect Bytebase to your database instances, configure authentication, and set up advanced security options.

## Quick Start

Navigate to the configuration section for your cloud provider, or start with general configuration options that apply to all databases:

<Columns cols={4}>
  <Card title="General Setup" href="#general-configuration" icon="settings" />
  <Card title="AWS" href="#aws-configuration" icon="aws" />
  <Card title="Google Cloud" href="#gcp-configuration" icon="google" />
  <Card title="Azure" href="#azure-configuration" icon="microsoft" />
</Columns>

## General Configuration

### Basic Connection

Before configuring connection parameters, ensure network connectivity:

**Network Requirements:**
- Verify network routing between Bytebase and your database instance (e.g., VPN, private networks)
- Configure firewall rules to allow Bytebase to connect to your database port
- For cloud databases, add Bytebase to security groups or IP allowlists
- Bytebase Cloud users: [Whitelist required IPs](/get-started/cloud#prerequisites)

**Connection Parameters:**

1. **Host**: Database server address
   - Docker (standard): Use `host.docker.internal` for localhost databases
   - Docker (--network host): Use `127.0.0.1` for localhost databases

2. **Port**: Database port number (e.g., 5432 for PostgreSQL, 3306 for MySQL)

3. **Username & Password**: Database credentials with appropriate permissions

Additional parameters vary by database type - see [Database-Specific Guides](#database-specific-guides) for your database's requirements.

### Read-Only Connections

Configure separate read-only connections for enhanced security and performance. Read-only connections are used for:
- SQL Editor queries with [data source restrictions](/sql-editor/settings/data-source-restriction)
- [Export Center operations](/security/database-permission/export#request-from-export-center)

**Setup:**
1. Create a read-only database user or configure a read-replica
2. In Bytebase, click **+** next to **Connection Info**
3. Enter the read-only connection details
4. Save the configuration

### SSH Tunnel

<PricingPlanBlock feature_name="SSH_TUNNEL" />

Use SSH tunneling to connect through a bastion host or jump server when your database is behind a firewall, in a private network, or requires specific security policies for access. This is common for databases in different VPCs or restricted network segments.

**Setup:**
1. Enter your database connection details as usual
2. Enable **SSH Connection** and select **Tunnel + Private Key**
3. Configure SSH tunnel settings:
   - **SSH Host**: Bastion host or jump server address
   - **SSH Port**: SSH port (typically 22)
   - **SSH User**: Username for SSH authentication
   - **Private Key** or **Password**: SSH authentication credentials
4. Test the connection and save

### Connection Parameters

Customize connection behavior with database-specific parameters:

**Common Parameters:**

| Parameter | Description | Example | Databases |
|-----------|------------|---------|-----------|
| `sslmode` | SSL connection mode | `require` | PostgreSQL |
| `connect_timeout` | Connection timeout | `10` | PostgreSQL, MySQL |
| `readTimeout` | Read operation timeout | `30s` | MySQL, SQL Server |
| `max_connections` | Maximum connections | `100` | All |

**Database Documentation:**
- [PostgreSQL Parameters](https://www.postgresql.org/docs/current/libpq-connect.html)
- [MySQL Parameters](https://github.com/go-sql-driver/mysql#parameters)
- [SQL Server Parameters](https://pkg.go.dev/github.com/microsoft/go-mssqldb#section-readme)
- [Oracle Parameters](https://github.com/sijms/go-ora)

### Secret Manager

<PricingPlanBlock feature_name="EXTERNAL_SECRET_MANAGER" />

Integrate with external secret managers for centralized credential management. Use this for corporate compliance, automatic password rotation, or when you prefer not to store credentials directly in Bytebase.

**Supported Providers:**
- **HashiCorp Vault** - Configure below
- **[AWS Secrets Manager](#aws-secrets-manager)** - See AWS configuration section
- **[GCP Secret Manager](#gcp-secret-manager)** - See GCP configuration section
- **Custom API Endpoint** - Configure below

#### HashiCorp Vault

<Note>
Requires Vault KV v2 engine
</Note>

**Vault Setup:**
1. Create secret in Vault:
   - Engine: `secret`
   - Path: `bytebase`
   - Key: `DB_PASSWORD`
   - Value: Your password

**Bytebase Configuration:**
1. Enter Vault URL
2. Choose authentication method:
   - **[Token](https://developer.hashicorp.com/vault/docs/auth/token)**: Provide access token
   - **[AppRole](https://developer.hashicorp.com/vault/docs/auth/approle)**: Provide role ID and secret ID
3. Specify secret location (engine/path/key)

#### Custom API Endpoint

Integrate with custom secret managers using your API:

**Endpoint Format:** `{{http://example.com/secrets/mydbkey}}`

**Expected Response:**
```json
{
  "payload": {
    "data": "base64_encoded_password"
  }
}
```

## AWS Configuration

### RDS/Aurora with IAM Authentication

This guide demonstrates the most secure method for IAM authentication using EC2 instance profiles, which eliminates the need to manage access keys. 

For alternative authentication methods such as IAM users with access keys or cross-account access, refer to:
- [AWS RDS IAM Database Authentication](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html)
- [Connecting using IAM authentication from the command line](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.Connecting.html)
- [IAM authentication for cross-account access](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.CrossAccount.html)

#### Step 1: Configure RDS/Aurora Instance

Enable IAM authentication on your database instance:

1. **Enable IAM Database Authentication**
   - For existing instances: Modify instance → Database authentication → IAM database authentication
   - For new instances: Enable "Password and IAM database authentication" during creation
   - Reference: [Enabling IAM authentication](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.Enabling.html)

2. **Verify SSL/TLS** 
   - SSL is enabled by default on RDS (required for IAM auth)
   - No additional configuration needed

#### Step 2: Create IAM Role for EC2

1. **Create IAM Policy**
   - Go to IAM → Policies → Create policy
   - Choose JSON and paste:
   ```json
   {
     "Version": "2012-10-17",
     "Statement": [
       {
         "Effect": "Allow",
         "Action": "rds-db:connect",
         "Resource": "arn:aws:rds-db:REGION:ACCOUNT_ID:dbuser:DB_INSTANCE_ID/DB_USER"
       }
     ]
   }
   ```
   - Replace `REGION`, `ACCOUNT_ID`, `DB_INSTANCE_ID`, and `DB_USER` with your values
   - Or use wildcards (*) for broader access
   - Name the policy: `rds-iam-auth-policy`
   
   > **Production Best Practice:** Use specific ARNs instead of wildcards. See [AWS IAM Policy examples](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.IAMPolicy.html).

2. **Create IAM Role**
   - Go to IAM → Roles → Create role
   - Select trusted entity: `AWS service` → `EC2`
   - Attach the `rds-iam-auth-policy` created above
   - Name: `bytebase-rds-role`

#### Step 3: Setup EC2 Instance with IAM Role

1. **Attach IAM Role to EC2**
   - New instances: Select `bytebase-rds-role` during launch configuration
   - Existing instances: EC2 console → Actions → Security → Modify IAM role → Select `bytebase-rds-role`

2. **Deploy Bytebase**
   - Install Bytebase on your EC2 instance
   - No AWS credentials configuration needed - the IAM role provides automatic authentication

#### Step 4: Create Database User

Connect to your RDS instance and create an IAM-authenticated user:

**MySQL/Aurora MySQL:**
```sql
CREATE USER 'bytebase'@'%' IDENTIFIED WITH AWSAuthenticationPlugin AS 'RDS';
ALTER USER 'bytebase'@'%' REQUIRE SSL;
GRANT ALL PRIVILEGES ON *.* TO 'bytebase'@'%';
```

**PostgreSQL/Aurora PostgreSQL:**
```sql
CREATE USER bytebase;
GRANT rds_iam TO bytebase;
-- Grant appropriate database permissions as needed
```

Reference: [MySQL setup](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.DBAccounts.html#UsingWithRDS.IAMDBAuth.DBAccounts.MySQL) | [PostgreSQL setup](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.DBAccounts.html#UsingWithRDS.IAMDBAuth.DBAccounts.PostgreSQL)

#### Step 5: Connect from Bytebase

Configure the database connection in Bytebase:

1. Click **New Instance** in Bytebase
2. Enter connection details:
   - **Host:** Your RDS endpoint (found in RDS console)
   - **Port:** 3306 (MySQL) or 5432 (PostgreSQL)
   - **Username:** `bytebase`
   - **Authentication:** Select `AWS RDS IAM`

3. Test and save the connection

Bytebase automatically handles IAM token generation and refresh using the EC2 instance role.

<Tip>
IAM authentication tokens expire after 15 minutes, but Bytebase automatically refreshes them using the instance profile. Learn more about [IAM database authentication limitations](https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAMDBAuth.html#UsingWithRDS.IAMDBAuth.Limitations).
</Tip>

### AWS Secrets Manager

#### Create an IAM user to access the Secrets Manager

<Tip>
It's recommended to create a dedicated IAM user for Bytebase to retrieve the secrets. You only need to do this once.
</Tip>

Visit [IAM](https://aws.amazon.com/iam/) to create a new IAM user. Name it `bytebase-external-secret`.

![](/content/docs/get-started/instance/aws-secrets-manager/iam-user-detail.webp)

Attach `SecretsManagerReadWrite` permission.

![](/content/docs/get-started/instance/aws-secrets-manager/iam-set-permission.webp)

After creating the IAM user, create an Access Key to be used by Bytebase later.

![](/content/docs/get-started/instance/aws-secrets-manager/iam-create-access-key.webp)

Select `Third-party service` as the use case.

![](/content/docs/get-started/instance/aws-secrets-manager/iam-access-key-use-case.webp)

Optionally set the description tag and in the `Retrieve access keys` screen, record `Access key` and `Secret access key`. They will be passed as environment variables when starting Bytebase.

![](/content/docs/get-started/instance/aws-secrets-manager/iam-access-key-info.webp)

#### Create secret

Visit [AWS Secrets Manager](https://aws.amazon.com/secrets-manager/) to store a new secret. Select `Other type of secret`, and add a key/value pair. The key is `DB_PASSWORD` and the value is your database user password.

![](/content/docs/get-started/instance/aws-secrets-manager/secret-type.webp)

Next to the `Configure secret`, use `bytebase` as the Secret name

![](/content/docs/get-started/instance/aws-secrets-manager/configure-secret.webp)

Skip rotation, review and create the secret.

#### Use secret in Bytebase

Restart Bytebase with the following environment variables:

```bash
docker run --init \
  -e AWS_REGION=us-east-1 \
  -e AWS_ACCESS_KEY_ID=xxx \
  -e AWS_SECRET_ACCESS_KEY=yyy \
  ...
```

Go to instance setting, specify `bytebase` as the Secret name and `DB_PASSWORD` as the Secret key. These two correspond to the value you created in the AWS Secrets Manager.

![](/content/docs/get-started/instance/aws-secrets-manager/auth.webp)

## GCP Configuration

### Prerequisites: Service Account Setup

Use attached service accounts for secure, key-free authentication on:
- **GCE** - VMs with attached service accounts
- **GKE** - Pods with Workload Identity

References: [Service accounts](https://cloud.google.com/iam/docs/service-account-overview) | [Best practices](https://cloud.google.com/iam/docs/best-practices-for-managing-service-account-keys) | [ADC](https://cloud.google.com/docs/authentication/application-default-credentials)

#### Create Service Account

1. Go to [IAM & Admin → Service Accounts](https://console.cloud.google.com/iam-admin/serviceaccounts)
2. Create service account named `bytebase`
3. Grant roles as needed:
   - `Cloud SQL Client` and `Cloud SQL Instance User` - for Cloud SQL
   - `Secret Manager Secret Accessor` - for Secret Manager
4. Note the email: `bytebase@PROJECT_ID.iam.gserviceaccount.com`

#### Attach Service Account

**Option A: GCE VM**
1. Create VM in [Compute Engine](https://console.cloud.google.com/compute/instances)
2. Set service account: `bytebase@PROJECT_ID.iam.gserviceaccount.com`
3. Set access scopes: "Allow full access to all Cloud APIs"

**Option B: GKE with Workload Identity**
```bash
# Create Kubernetes service account
kubectl create serviceaccount bytebase-ksa

# Bind to Google service account
kubectl annotate serviceaccount bytebase-ksa \
  iam.gke.io/gcp-service-account=bytebase@PROJECT_ID.iam.gserviceaccount.com

# Allow impersonation
gcloud iam service-accounts add-iam-policy-binding bytebase@PROJECT_ID.iam.gserviceaccount.com \
  --role roles/iam.workloadIdentityUser \
  --member "serviceAccount:PROJECT_ID.svc.id.goog[NAMESPACE/bytebase-ksa]"
```

Reference: [Workload Identity](https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity)

Deploy Bytebase on your resource - credentials are provided automatically.

#### Alternative: Service Account Keys

<Warning>
Use only when running Bytebase outside GCP. See [why to avoid service account keys](https://cloud.google.com/iam/docs/best-practices-for-managing-service-account-keys#avoid).
</Warning>

1. Create a service account with required roles
2. Download the JSON key file
3. Set environment variable:
   ```bash
   -e GOOGLE_APPLICATION_CREDENTIALS=/path/to/key.json
   ```

Reference: [Service account keys authentication](https://cloud.google.com/docs/authentication/provide-credentials-adc#local-key)

### Cloud SQL with IAM Authentication

<Note>
Prerequisites: [Service account](#prerequisites-service-account-setup) with Cloud SQL roles.
</Note>

References: [IAM authentication](https://cloud.google.com/sql/docs/mysql/iam-authentication) | [Configure instances](https://cloud.google.com/sql/docs/mysql/create-edit-iam-instances)

#### Step 1: Configure Cloud SQL Instance

1. In [Cloud SQL](https://console.cloud.google.com/sql/instances), edit your instance
2. Add flag: `cloudsql_iam_authentication` = `on`
3. Save (SSL is enabled by default)

#### Step 2: Add Service Account User

**Using gcloud:**
```bash
gcloud sql users create bytebase@PROJECT_ID.iam.gserviceaccount.com \
  --instance=INSTANCE_NAME \
  --type=cloud_iam_service_account
```

**Using Console:**
Instance → Users → Add User Account → Cloud IAM → Enter service account email

References: [MySQL](https://cloud.google.com/sql/docs/mysql/add-manage-iam-users) | [PostgreSQL](https://cloud.google.com/sql/docs/postgres/add-manage-iam-users)

#### Step 3: Connect from Bytebase

1. Click **New Instance** in Bytebase
2. Configure connection details:
   - **Host:** Your Cloud SQL connection name (`PROJECT_ID:REGION:INSTANCE_ID`)
     - Find this in Cloud SQL console → Instance details
   - **Port:** 3306 (MySQL) or 5432 (PostgreSQL)
   - **Username:** 
     - MySQL: `bytebase` (service account name only)
     - PostgreSQL: `bytebase@PROJECT_ID.iam` (with project ID)
   - **Authentication:** Select `Google Cloud SQL IAM`
3. Click **Test Connection** then **Create**

### GCP Secret Manager

Store database passwords securely in Google Cloud Secret Manager instead of Bytebase.

<Note>
Prerequisites: [Service account](#prerequisites-service-account-setup) with `Secret Manager Secret Accessor` role.
</Note>

#### Step 1: Create Secret

1. Go to [Secret Manager Console](https://console.cloud.google.com/security/secret-manager)
2. Click **Create Secret**
3. Enter secret name (e.g., `db-password`) and your database password as value
4. Click **Create** and note the resource name: `projects/PROJECT_ID/secrets/SECRET_NAME`

#### Step 2: Configure in Bytebase

1. In your database instance settings, find the password field
2. Click the key icon to use external secret
3. Select **GCP Secret Manager** 
4. Enter the secret resource name from Step 1
5. Test connection and save

## Azure Configuration

### Azure SQL with Managed Identity Authentication

This guide demonstrates the most secure method for connecting to Azure SQL Database and Azure SQL Managed Instance using VM-attached managed identities, eliminating the need to manage credentials or connection strings.

For alternative authentication methods and detailed configuration options, refer to:
- [Azure SQL authentication methods overview](https://learn.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-overview)
- [Managed identities for Azure resources](https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/overview)
- [Configure Azure AD authentication for SQL Database](https://learn.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-configure)
- [Connect to Azure SQL with managed identity](https://learn.microsoft.com/en-us/azure/azure-sql/database/authentication-azure-ad-user-assigned-managed-identity)

#### Step 1: Create Azure VM with System-Assigned Managed Identity

1. **Create VM with Managed Identity**
   - Go to [Azure Portal → Virtual Machines](https://portal.azure.com/#blade/HubsExtension/BrowseResource/resourceType/Microsoft.Compute%2FVirtualMachines)
   - Click **Create** → **Azure virtual machine**
   - Configure VM settings as needed
   - Under **Management** tab:
     - Enable **System assigned managed identity**: Set to **On**
   - Complete VM creation
   
   > **Security Best Practice:** System-assigned managed identities are automatically managed by Azure and tied to the VM lifecycle. This eliminates credential management and reduces security risks. Learn more: [Managed identity best practices](https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/managed-identity-best-practice-recommendations)

2. **Deploy Bytebase on the VM**
   
   Deploy Bytebase on your Azure VM. The VM's managed identity is automatically available - no credential configuration needed.

#### Step 2: Configure Azure SQL Database

1. **Enable Microsoft Entra Authentication**
   - Navigate to your Azure SQL Server in [Azure Portal](https://portal.azure.com)
   - Go to **Settings** → **Microsoft Entra ID**
   - Click **Set admin** and select an Entra admin account
   - Click **Save** to enable Entra authentication
   
   Reference: [Configure Entra authentication for Azure SQL](https://learn.microsoft.com/en-us/azure/azure-sql/database/authentication-aad-configure)

2. **Grant Database Access to Managed Identity**
   - Note your VM's managed identity name (same as VM name)
   - Connect to Azure SQL using the Entra admin account
   - Run the following for each database:

   ```sql
   -- Create user for the VM's managed identity
   CREATE USER [your-vm-name] FROM EXTERNAL PROVIDER;
   
   -- Grant appropriate permissions (adjust as needed)
   ALTER ROLE db_datareader ADD MEMBER [your-vm-name];
   ALTER ROLE db_datawriter ADD MEMBER [your-vm-name];
   ALTER ROLE db_ddladmin ADD MEMBER [your-vm-name];
   
   -- For full database management in Bytebase:
   ALTER ROLE db_owner ADD MEMBER [your-vm-name];
   ```
   
   > **Production Best Practice:** Follow the principle of least privilege. Grant only the minimum permissions required for your use case. See [Azure SQL Database permissions](https://learn.microsoft.com/en-us/azure/azure-sql/database/logins-create-manage).

#### Step 3: Connect from Bytebase

1. Access Bytebase on your VM (typically `http://localhost:5678`)
2. Click **New Instance**
3. Configure the connection:
   - **Host:** Your Azure SQL server name (e.g., `yourserver.database.windows.net`)
   - **Port:** 1433
   - **Database:** Target database name
   - **Authentication:** Select `Azure Default Credential`
4. Test and save the connection

Bytebase automatically uses the VM's managed identity through Azure's Instance Metadata Service (IMDS) for authentication.

<Tip>
**Advantages of this approach:**
- No passwords or connection strings to manage
- Automatic credential rotation handled by Azure
- Enhanced security through Azure RBAC
- Simplified compliance and auditing

For troubleshooting, see [Troubleshoot managed identity authentication](https://learn.microsoft.com/en-us/azure/azure-sql/database/authentication-azure-ad-user-assigned-managed-identity#troubleshooting).
</Tip>

#### Alternative: User-Assigned Managed Identity

For more granular control or cross-resource scenarios:

1. **Create User-Assigned Managed Identity**
   - Go to [Managed Identities](https://portal.azure.com/#blade/HubsExtension/BrowseResource/resourceType/Microsoft.ManagedIdentity%2FuserAssignedIdentities)
   - Create a new identity with a descriptive name
   - Assign it to your VM under **Settings** → **Identity** → **User assigned**

2. **Configure Database Access**
   ```sql
   CREATE USER [managed-identity-name] FROM EXTERNAL PROVIDER;
   ALTER ROLE db_owner ADD MEMBER [managed-identity-name];
   ```

3. **Set Environment Variable** (if using multiple identities)
   ```bash
   export AZURE_CLIENT_ID=<managed-identity-client-id>
   ```

Reference: [User-assigned managed identities](https://learn.microsoft.com/en-us/entra/identity/managed-identities-azure-resources/how-manage-user-assigned-managed-identities)

## Database-Specific Guides

Configure connection settings for specific database types:

<Tabs>
  <Tab title="PostgreSQL">
    <PostgreSQLConfig />
  </Tab>
  <Tab title="Oracle">
    <OracleConfig />
  </Tab>
  <Tab title="MongoDB">
    <MongoDBConfig />
  </Tab>
  <Tab title="Snowflake">
    <SnowflakeConfig />
  </Tab>
  <Tab title="ClickHouse">
    <ClickHouseConfig />
  </Tab>
  <Tab title="Databricks">
    <DatabricksConfig />
  </Tab>
  <Tab title="Spanner">
    <SpannerConfig />
  </Tab>
</Tabs>

